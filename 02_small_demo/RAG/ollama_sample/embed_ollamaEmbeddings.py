"""
åµŒå…¥å’Œå‘é‡æ•°æ®åº“æ¨¡å— (Embedding and Vector Database Module)

åŠŸèƒ½ï¼šä½¿ç”¨ Ollama ç”Ÿæˆæ—¥æ–‡/ä¸­æ–‡è¯­ä¹‰å‘é‡ï¼Œå¹¶æŒä¹…åŒ–å­˜å‚¨åˆ° ChromaDBã€‚
æ¨¡å‹ï¼šé»˜è®¤ä½¿ç”¨ bge-m3 (æ”¯æŒå¤šè¯­è¨€ï¼Œä¸Šä¸‹æ–‡çª—å£ 8192)ã€‚


ChromaDB çš„è®¾è®¡æ˜¯æ”¯æŒâ€œä¸€æ¬¡å­˜ä¸€å †â€çš„ï¼Œæ‰€ä»¥å³ä¾¿ä½ åªå­˜ä¸€ä¸ªï¼Œä¹Ÿè¦åŒ…ä¸€å±‚ï¼š
    ids: ["id1"]
    documents: ["å†…å®¹1"]
    embeddings: [[0.1, 0.2, ...]] ï¼ˆæ³¨æ„è¿™æ˜¯åˆ—è¡¨å¥—åˆ—è¡¨ï¼‰
"""

import chromadb
import my_chunk as chunk_module  # ç¡®ä¿æ–‡ä»¶åå·²æ”¹ä¸º my_chunk.py
from langchain_ollama import OllamaEmbeddings
from pathlib import Path

# --- 1. ç¯å¢ƒä¸è·¯å¾„é…ç½® ---

# è·å–å½“å‰è„šæœ¬æ‰€åœ¨ç›®å½•ï¼Œå¹¶åœ¨å…¶ä¸‹åˆ›å»º db æ–‡ä»¶å¤¹
current_dir: Path = Path(__file__).resolve().parent
db_path: Path = current_dir / "db"
db_path.mkdir(exist_ok=True) # è‡ªåŠ¨åˆ›å»º db æ–‡ä»¶å¤¹ï¼Œå¦‚æœå·²å­˜åœ¨åˆ™è·³è¿‡

# åˆå§‹åŒ– LangChain æä¾›çš„ Ollama åµŒå…¥ç±» (å®ƒä¼šè‡ªåŠ¨è°ƒç”¨æœ¬åœ° 11434 ç«¯å£)
# è¿™æ ·åšå°±ä¸éœ€è¦è‡ªå·±å†™ requests.post äº†ï¼Œæ›´ä¼˜é›…
embedder = OllamaEmbeddings(model="bge-m3")

# --- 2. ChromaDB åˆå§‹åŒ– ---

# è¿™é‡Œçš„è·¯å¾„æŒ‡å‘ db æ–‡ä»¶å¤¹ä¸‹çš„ chroma.db å­ç›®å½•
chromadb_client: chromadb.ClientAPI = chromadb.PersistentClient(path=str(db_path / "chroma.db"))

def get_embedding(text: str) -> list[float]:
    """
    é€šè¿‡ LangChain å°è£…è°ƒç”¨ Ollama ç”Ÿæˆå•ä¸ªæ–‡æœ¬çš„å‘é‡ã€‚
    """
    try:
        return embedder.embed_query(text)
    except Exception as e:
        raise Exception(f"ç”Ÿæˆå‘é‡å¤±è´¥ï¼Œè¯·æ£€æŸ¥ Ollama æ˜¯å¦å¯åŠ¨: {e}")
    

#å¾ªç¯å•ä¸ªæ–‡ä»¶ æ„Ÿè§‰ä¸å¤ªå¥½çš„æ ·å­
def add_document_to_db() -> None:
    """
    è¯»å–æ–‡æœ¬å—ï¼Œç”Ÿæˆå‘é‡å¹¶å­˜å…¥æ•°æ®åº“ã€‚
    """
    print("ğŸš€ æ­£åœ¨å¯åŠ¨å‘é‡æ•°æ®åº“åˆ›å»ºç¨‹åº...")
    collection : chromadb.Collection =delete_create_collection()
    
    # è¿™é‡Œçš„ chunks åº”è¯¥æ˜¯ä¸€ä¸ªå­—ç¬¦ä¸²æ•°ç»„ï¼Œä¾‹å¦‚ ["ç¬¬ä¸€æ®µæ–‡å­—", "ç¬¬äºŒæ®µæ–‡å­—", ...]
    chunks: list[str] = chunk_module.get_chunks()
    
    if not chunks:
        print("âŒ æœªè·å–åˆ°ä»»ä½•æ–‡æœ¬å—ï¼Œè¯·æ£€æŸ¥ my_chunk.py")
        return

    for idx, c in enumerate(chunks):
        print(f"ğŸ“¦ å¤„ç†è¿›åº¦ {idx+1}/{len(chunks)}: {c[:30]}...")
        
        # è·å–å½“å‰å—çš„å‘é‡ (bge-m3 è¿”å›çš„æ˜¯ 1024 ç»´åˆ—è¡¨)
        vector: list[float] = get_embedding(c)
        
        
        # upsert æ˜¯ Updateï¼ˆæ›´æ–°ï¼‰ + Insertï¼ˆæ’å…¥ï¼‰ çš„ç¼©å†™ã€‚ å®ƒçš„é€»è¾‘å¦‚ä¸‹ï¼š
        #     å¦‚æœ ID å·²å­˜åœ¨ï¼šå®ƒä¼šç”¨æ–°çš„ document å’Œ embedding æ›¿æ¢ï¼ˆè¦†ç›–ï¼‰ æ‰æ—§çš„å†…å®¹ã€‚
        #     å¦‚æœ ID ä¸å­˜åœ¨ï¼šå®ƒä¼šæ–°å¢ä¸€æ¡è®°å½•ã€‚      
          
        # å­˜å…¥ ChromaDB
        # æ³¨æ„ï¼šå³ä¾¿ c æ˜¯å­—ç¬¦ä¸²ï¼Œä¹Ÿè¦å†™æˆ [c] ä»¥ç¬¦åˆ API çš„æ‰¹é‡è¾“å…¥è¦æ±‚
        collection.upsert(
            ids=[f"chunk_{idx}"],      # ID å¿…é¡»æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨
            documents=[c],             # æ–‡æ¡£å¿…é¡»æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨
            embeddings=[vector]        # å‘é‡å¿…é¡»æ˜¯åµŒå¥—åˆ—è¡¨ [[...]]
        )
        
    print("âœ… å‘é‡æ•°æ®åº“å·²æˆåŠŸæ›´æ–°å¹¶æŒä¹…åŒ–å­˜å‚¨ã€‚")



def add_documents_to_db() -> None:
    """
    ã€é«˜æ€§èƒ½ç‰ˆã€‘ä¸€æ¬¡æ€§è¯»å–æ‰€æœ‰å—å¹¶æ‰¹é‡å­˜å…¥æ•°æ®åº“ã€‚
    """
    print("ğŸš€ æ­£åœ¨æ‰¹é‡å¤„ç†å‘é‡æ•°æ®åº“...")
    collection : chromadb.Collection =delete_create_collection()   

    # 1. è·å–æ‰€æœ‰å— (å‡è®¾è¿™æ˜¯ä¸€ä¸ªåˆ—è¡¨: ["å†…å®¹1", "å†…å®¹2", ...])
    chunks: list[str] = chunk_module.get_chunks()
    
    if not chunks:
        return

    # 2. ã€å…³é”®ã€‘è°ƒç”¨æ‰¹é‡ç”Ÿæˆå‘é‡æ¥å£ (ä¸€æ¬¡æ€§æŠŠæ•´ä¸ªæ•°ç»„ä¼ è¿›å»)
    # è¿™æ¯”åœ¨å¾ªç¯é‡Œä¸€ä¸ªä¸€ä¸ª get_embedding å¿«å¾—å¤šï¼
    all_embeddings: list[list[float]] = embedder.embed_documents(chunks)
    
    # 3. ã€å…³é”®ã€‘ç”Ÿæˆ ID åˆ—è¡¨ (ä¾‹å¦‚: ["chunk_0", "chunk_1", ...])
    all_ids: list[str] = [f"chunk_{i}" for i in range(len(chunks))]
    
    # 4. ä¸€æ¬¡æ€§å†™å…¥æ•°æ®åº“
    # è¿™é‡Œä¸éœ€è¦åŠ æ–¹æ‹¬å·äº†ï¼Œå› ä¸º chunks, all_embeddings, all_ids æœ¬èº«å°±æ˜¯åˆ—è¡¨
    collection.upsert(
        ids=all_ids,
        documents=chunks,
        embeddings=all_embeddings
    )
    
    print(f"âœ… æˆåŠŸä¸€æ¬¡æ€§å­˜å…¥ {len(chunks)} æ¡æ–‡æ¡£ç‰‡æ®µï¼")



def query_db(question: str, n_results: int = 5) -> list[str]:
    """
    æœç´¢æœ€ç›¸å…³çš„æ–‡æœ¬å—ã€‚
    """
    print(f"ğŸ” æ­£åœ¨æŸ¥è¯¢: {question}")
    collection : chromadb.Collection = chromadb_client.get_or_create_collection("japanese_docs_ollama")
    
    # 1. å…ˆæŠŠé—®é¢˜è½¬æ¢æˆå‘é‡
    question_vector: list[float] = get_embedding(question)
    
    # 2. åœ¨æ•°æ®åº“ä¸­æ£€ç´¢
    result = collection.query(
        query_embeddings=[question_vector], # æ³¨æ„åµŒå¥—
        n_results=n_results
    )
    
    # result['documents'] çš„ç»“æ„æ˜¯ [[doc1, doc2, ...]]
    if result["documents"] and len(result["documents"]) > 0:
        return result["documents"][0]
    return []



def delete_create_collection()  -> chromadb.Collection:
    """
    è·å–æˆ–åˆ›å»º ChromaDB é›†åˆ (Collection)ã€‚
    """
    # è·å–æ‰€æœ‰ç°æœ‰çš„ ID å¹¶åˆ é™¤ï¼Œæˆ–è€…ç›´æ¥åˆ é™¤æ•´ä¸ª Collection
    try:
        # ç®€å•çš„åšæ³•ï¼šå¦‚æœå­˜åœ¨ï¼Œå…ˆåˆ æ‰è¿™ä¸ªé›†åˆå†é‡å»º
        chromadb_client.delete_collection("japanese_docs_ollama")
    except:
        pass
    # åˆ›å»ºæˆ–è·å–é›†åˆã€‚æ³¨æ„ï¼šå¦‚æœä» nomic æ¢åˆ° bge-m3ï¼Œå»ºè®®æ”¹ä¸ªåå­—æˆ–åˆ é™¤æ—§ db æ–‡ä»¶å¤¹
    return  chromadb_client.get_or_create_collection("japanese_docs_ollama")

# --- 3. æµ‹è¯•è¿è¡Œ ---

if __name__ == '__main__':
    # 1. éªŒè¯æ¨¡å‹å’Œå‘é‡é•¿åº¦
    print("--- æ­£åœ¨æµ‹è¯• BGE-M3 æ¨¡å‹ ---")
    test_vec: list[float] = get_embedding("ã“ã‚“ã«ã¡ã¯")
    print(f"å‘é‡ç»´åº¦: {len(test_vec)}") # åº”è¯¥è¾“å‡º 1024

    # 2. åˆ›å»º/æ›´æ–°æ•°æ®åº“
    # add_document_to_db()

    # 3. æ‰§è¡Œä¸€æ¬¡æ£€ç´¢æµ‹è¯•
    question = "ä»¤ç‹å†²é¢†æ‚Ÿäº†ä»€ä¹ˆé­”æ³•ï¼Ÿ"
    results: list[str] = query_db(question)
    
    print("\n--- æ£€ç´¢åˆ°çš„ç›¸å…³ç‰‡æ®µ ---")
    for i, res in enumerate(results):
        print(f"[{i+1}] {res[:150]}...\n")