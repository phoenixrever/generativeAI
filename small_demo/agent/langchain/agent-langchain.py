"""
2. å¦‚ä½•æŸ¥çœ‹æˆ‘çš„é¢åº¦ä½¿ç”¨æƒ…å†µï¼Ÿ
ä½ å¯ä»¥é€šè¿‡ä»¥ä¸‹ä¸¤ä¸ªå®˜æ–¹å…¥å£æŸ¥çœ‹å®æ—¶æ•°æ®ï¼š

Google AI Studio ä»ªè¡¨æ¿:

è®¿é—® https://aistudio.google.com/app/plan_usage

è¿™é‡Œèƒ½ç›´è§‚çœ‹åˆ°ä½ ä»Šå¤©ç”¨äº†å¤šå°‘æ¬¡ï¼Œè¿˜å‰©å¤šå°‘ã€‚

Google Cloud Console (æ›´è¯¦ç»†):

è®¿é—® https://console.cloud.google.com/apis/api/generativelanguage.googleapis.com/quotas

åœ¨è¿™é‡Œä½ å¯ä»¥çœ‹åˆ°å…·ä½“çš„â€œæ¯åˆ†é’Ÿè¯·æ±‚æ•°â€æ›²çº¿ã€‚
"""


import asyncio
from dotenv import load_dotenv

# LangChain ç›¸å…³å¯¼å…¥
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.messages import HumanMessage
from langchain.agents import create_agent
from langgraph.checkpoint.memory import MemorySaver  # å†…å­˜è®°å¿†å­˜å‚¨å™¨

# å¯¼å…¥ä½ å†™çš„å·¥å…·
import tools

load_dotenv()

# 1. é…ç½®æ¨¡å‹ (ç¡®ä¿ç¯å¢ƒå˜é‡ä¸­æœ‰ GOOGLE_API_KEY)
model = ChatGoogleGenerativeAI(
    model="gemini-2.0-flash-lite", 
    streaming=True,
    temperature=0  # è®¾ç½®ä¸º 0 è®©ç¼–ç¨‹ä»»åŠ¡æ›´ä¸¥è°¨
)

# 2. ç»„è£…å·¥å…·é›†
langchain_tools = [tools.read_file, tools.list_files, tools.rename_file]

# 3. è®¾ç½®è®°å¿†å­˜å‚¨ (Checkpointer)
# MemorySaver ä¼šåœ¨ç¨‹åºè¿è¡ŒæœŸé—´è®°ä½å¯¹è¯ï¼Œå¦‚æœæƒ³é‡å¯ç¨‹åºä¹Ÿè®°ä½ï¼Œå¯ä»¥æ¢æˆ SqliteSaver
memory = MemorySaver()

# 4. åˆ›å»º Agent
system_prompt = "You are a professional Python programmer. Use the provided tools to manage files."
agent_executor = create_agent(
    model, 
    tools=langchain_tools, 
    checkpointer=memory,
    system_prompt=system_prompt
)

async def chat_loop():
    # thread_id æ˜¯è®°å¿†çš„â€œé’¥åŒ™â€ï¼Œç›¸åŒçš„ ID å¯¹åº”åŒä¸€ä¸ªäººçš„å¯¹è¯
    config = {"configurable": {"thread_id": "user_1"}}
    
    print("ğŸš€ Agent å·²å°±ç»ª! (è¾“å…¥ 'exit' é€€å‡º)")
    print(f"ğŸ“ å½“å‰å·¥ä½œç›®å½•: {tools.base_dir.absolute()}")

    while True:
        user_input = input("\nUser >>> ")
        if user_input.lower() in ["exit", "quit"]:
            break

        # 5. ä½¿ç”¨ astream è¿›è¡Œæµå¼å¤„ç†
        # stream_mode="messages" å¯ä»¥è®©æˆ‘ä»¬æ•è·åˆ°æ‰€æœ‰æ¶ˆæ¯å—
        print("AI >>> ", end="", flush=True)
        
        # æˆ‘ä»¬åªå‘é€å½“å‰è¿™ä¸€æ¡æ¶ˆæ¯ï¼ŒLangGraph ä¼šè‡ªåŠ¨ä» memory ä¸­æå–å†å²è®°å½•
        inputs = {"messages": [HumanMessage(content=user_input)]}
        
        async for msg, metadata in agent_executor.astream(
            inputs, 
            config=config, 
            stream_mode="messages"
        ):
            # å¤„ç† AI çš„æ–‡æœ¬è¾“å‡º
            if msg.content and not isinstance(msg, HumanMessage):
                print(msg.content, end="", flush=True)
            
            # å¤„ç†å·¥å…·è°ƒç”¨åé¦ˆ (è®©ç”¨æˆ·çŸ¥é“ AI åœ¨å¹²å˜›)
            if hasattr(msg, "tool_calls") and msg.tool_calls:
                for tc in msg.tool_calls:
                    print(f"\nğŸ› ï¸  [æ­£åœ¨æ‰§è¡Œ: {tc['name']} å‚æ•°: {tc['args']}]", flush=True)
        
        print() # æ¢è¡Œ

if __name__ == "__main__":
    try:
        asyncio.run(chat_loop())
    except KeyboardInterrupt:
        print("\nç¨‹åºå·²åœæ­¢")