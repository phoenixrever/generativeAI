# TODO å¼‚æ­¥ç›®å‰è¿˜æ˜¯ä¸èµ·ä½œç”¨
import asyncio
# éœ€è¦å®‰è£…: pip install aioconsole
import aioconsole 
from langchain_ollama import ChatOllama
from langchain_core.messages import HumanMessage
from langchain.agents import create_agent
from langgraph.checkpoint.memory import MemorySaver

# å‡è®¾ä½ çš„ tools å·²ç»å®šä¹‰å¥½äº†
import tools

async def chat_loop():
    # 1. åˆå§‹åŒ–æ¨¡å‹
    model = ChatOllama(
        model="qwen3:1.7b",
        temperature=0,
        streaming=True
    )

    # 2. ç»„è£…å·¥å…·
    langchain_tools = [tools.read_file, tools.list_files, tools.rename_file]

    # 3. è®¾ç½®è®°å¿†
    memory = MemorySaver()

    # 4. åˆ›å»º Agent (ä½¿ç”¨æœ€æ–°çš„ create_react_agent é¿å…æ—§ç‰ˆåŒæ­¥é˜»å¡)
    system_prompt = "You are a professional Python programmer. Use the provided tools to manage files."
    agent_executor = create_agent(
        model, 
        tools=langchain_tools, 
        checkpointer=memory,
        system_prompt=system_prompt # æ–°ç‰ˆå‚æ•°å
    )

    config = {"configurable": {"thread_id": "async_local_user"}}
    print("ğŸš€ å¼‚æ­¥ Ollama Agent å·²å¯åŠ¨!")

    while True:
        # ä½¿ç”¨ aioconsole.ainput é˜²æ­¢é˜»å¡å¼‚æ­¥äº‹ä»¶å¾ªç¯
        user_input = await aioconsole.ainput("\nUser >>> ")
        
        if user_input.lower() in ["exit", "quit"]:
            break

        print("AI >>> ", end="", flush=True)
        
        # é‡ç‚¹ï¼šä½¿ç”¨ astream é…åˆ stream_mode="messages"
        async for token, metadata in agent_executor.astream(
            {"messages": [HumanMessage(content=user_input)]},
            config=config,
            stream_mode="messages",
        ):
            # å¤„ç† Token ç‰‡æ®µ
            if hasattr(token, "content_blocks") and token.content_blocks:
                block = token.content_blocks[0]
                if isinstance(block, dict) and block.get("type") == "text":
                    print(block.get("text", ""), end="", flush=True)
                # å¤„ç†æŸäº›ç‰ˆæœ¬å¯èƒ½è¿”å›å¯¹è±¡çš„æƒ…å†µ
                elif hasattr(block, "text"):
                    print(block.text, end="", flush=True)
            
            # å¤„ç†å·¥å…·èŠ‚ç‚¹æ˜¾ç¤º
            node_name = metadata.get('langgraph_node')
            if node_name == 'tools':
                # æ³¨æ„ï¼šåœ¨ astream ä¸­ï¼Œå·¥å…·èŠ‚ç‚¹å¯èƒ½ä¼šå¤šæ¬¡è§¦å‘äº‹ä»¶ï¼Œè¿™é‡Œç®€å•å»é‡æ‰“å°
                pass 

        print() 

if __name__ == "__main__":
    # ä½¿ç”¨ asyncio.run å¯åŠ¨
    try:
        asyncio.run(chat_loop())
    except KeyboardInterrupt:
        pass